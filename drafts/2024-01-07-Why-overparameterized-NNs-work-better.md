layout: post
title: Why overparameterized NNs work better
date: 2024-01-07 19:37:50
---

Статья [Deep double descent](https://openai.com/research/deep-double-descent) заканчивается словами:

```
Our intuition is that, for models at the interpolation threshold, there is effectively only one model that fits the train data, and forcing it to fit even slightly noisy or misspecified labels will destroy its global structure.
```

По поводу этого предположения я вообще имею наглость сказать, что я не верю в него.

Во-первых, мне не нравится недоказанное утверждение, что есть только одна модель, которая подходит под тренировочные данные. Другое дело, что даже если таких моделей много, то веса у них могут отличаться, а производительность нет.

Однако, на самом деле это даже не суть. Суть в том, что моя интуиция по этому вопросу другая. Я думаю, что если нейронка пытается запомнить мусор, а свободных нейронов не хватает, то ей приходится задествовать существующие связи между нейронами. Накладывать новую информацию поверх уже выученной. Естественно это приводит к шуму в весах для выученной информации. В глазах начинает двоиться.

Если же нейронов дофига, то сетка сможет разнести шум и данные в разные стороны, буквально выделив отдельные участки нейронки под шум. Нейроны, которые занимаются обобщением, при этом не пострадают.

На основании своей гипотезы я могу сделать два предположения.

Первое - вангую, что если продолжать увеличивать количество параметров сетки, то можно таки дойти до второго подъема ошибки. Т.е. сетка опять начнет переобучаться, если ее размер будет достаточно большим. Я так понял, что они в своем исследовании увеличивали размер сетки до k=64, что соответствует дефолтному размеру сетки. Ну блин... надо было увеличить размер еще хотябы в 10 раз для чистоты эксперимента. А то так я считаю исследование не завершенным.

Второе - вангую, что увеличивать важнее последний слой, а не сверточные слои. Потому что именно в последних слоях ожидается логика разделения на классы. Для проверки этой гипотезы я предлагаю повторить эксперименты, но менять размер только последнего слоя. А первые конволюционные слои оставить дефолтного размера. Есть правда опасность, что при нехватке нейронов в последнем слое логика классификации начнет просачиваться в сверточные слои. Но проверить было бы интересно.